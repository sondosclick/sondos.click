---
layout: post
title: "Ask the AI. The new sondosclicks."
date: 2026-02-01
categories: [AI, Technology, Culture]
tags: [AI, Productivity, Complexity, Critical Thinking, Automation]
description: "Why “ask the AI” is the new “two clicks” and how complexity doesn’t disappear, it just moves."
featureimage: "/images/posts/2026-02-01-pidelo-a-la-ia-el-nuevo-sondos-clicks/feature.png"
---
# Ask the AI. The new *sondosclicks*

![Illustration about asking AI for everything](/images/posts/2026-02-01-pidelo-a-la-ia-el-nuevo-sondos-clicks/feature.png)

For years, in tech, we survived thanks to a reassuring phrase.  
One of those phrases that turns weeks of work, uncomfortable decisions, and real risks into something almost domestic.

> *“That’s two clicks.”*

It didn’t matter if we were talking about cloud, automation, or architecture.  
There was always someone ready to reduce the problem to a magical combo of simplicity and optimism.

Today that phrase has evolved.

It’s now more modern, more elegant, and far more convincing:

> **“Ask the AI.”**

And the unsettling thing is that it creates exactly the same effect.



The phrase works because AI is impressive. A lot.  
It responds fast, writes well, and almost always returns something that *looks* reasonable. You ask for something and it responds. You ask for more and it improves. You correct it and it adapts. It’s like a **black box with a smile**: you don’t really know what’s inside, but it talks with such confidence that you end up trusting it.

![Illustration about the AI-as-shortcut promise](/images/posts/2026-02-01-pidelo-a-la-ia-el-nuevo-sondos-clicks/scene-1.png)

From the outside, the conclusion seems obvious:  
if the box answers in seconds, maybe the problem was never that complex.

Spoiler: it was.

With cloud we learned this lesson late. Provisioning infrastructure turned out to be trivial. Operating it well, governing it, and sustaining it over time… not so much. The famous “two clicks” didn’t eliminate complexity; they just hid it behind a friendly interface. The difficulty was still there, waiting for someone to ignore it long enough.



With AI we’re repeating the pattern, only now the interface is natural language and the box answers with more confidence than ever. Before the message was “don’t worry, it’s two clicks.” Now it’s “don’t worry, ask the AI.” The calm is the same. The risk too.

![Illustration about complexity hiding behind a friendly interface](/images/posts/2026-02-01-pidelo-a-la-ia-el-nuevo-sondos-clicks/scene-2.png)

Let’s imagine—in a purely fictional exercise—a situation that *never* happens in real companies.  
An executive says something like:

> “We need a system that analyzes customer emails, detects incidents, prioritizes by urgency, generates automated replies, and learns over time. But quickly, because with AI this is easy.”

Someone obeys. They ask the box.



The black box responds with a reasonable design, some code, an elegant flow, and reassuring words like *pipeline*, *feedback loop*, and *continuous improvement*. Everything seems to fit. Problem solved.

Until someone asks uncomfortable questions.  
What if the email is sarcastic?  
Who decides what’s urgent?  
What biases is the box carrying?  
What happens when an angry customer gets a perfectly optimized… and completely inappropriate reply?  
Who explains that “the box decided”?

The box has generated a response.  
The system, in reality, was never designed.

![Illustration about asking AI to build a full system](/images/posts/2026-02-01-pidelo-a-la-ia-el-nuevo-sondos-clicks/scene-3.png)



Here’s the core problem. We confuse generation with resolution. The box produces *outputs* with astonishing ease, and that fools us. Because real systems don’t fail from lack of text, code, or ideas. They fail from bad decisions, unspoken assumptions, ignored context, and fuzzy responsibility.

None of that disappears because someone wrote it fast… or because a box wrote it.

The problem isn’t using AI. The problem is starting to **give it authority**. “Ask the AI” suggests that understanding is optional, that validation is secondary, and that thinking is a bottleneck to be removed. And the more we trust the box, the less we question it.

Complexity hasn’t disappeared. It’s just moved. Before it lived in the code or the infrastructure. Now it lives in judgment, validation, and final responsibility. It’s invisible, silent, and very convenient… until it fails.

And when it fails, it fails with a particular unease:  
nobody feels like they actually made the decision.

![Illustration about the gap between generating and solving](/images/posts/2026-02-01-pidelo-a-la-ia-el-nuevo-sondos-clicks/scene-4.png)

The next time someone says:

> “Ask the AI.”

Maybe it deserves a less friendly response:

> “Sure.  
> Who answers when the box gets it wrong?  
> Who takes the consequences?  
> And why are we so ready to obey something that doesn’t think, but speaks with such confidence?”

Because no, it’s not the new *sondosclicks*.  
It’s worse.

It’s delegating judgment to a black box…  
and feeling relieved for having done it.

---

{{< smallnote >}}
**Note**: This article begins a series in which I’ll try to separate legitimate enthusiasm for AI from the magical thinking that often accompanies it. We start by talking about simplification and complexity, but the conversation will drift—inevitably—toward authority, bias, ethics, and real-world consequences. I don’t know how many articles there will be or how far the series will go. For now, it starts here.
{{< /smallnote >}}
