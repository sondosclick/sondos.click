---
layout: post
title: "Decisiones sin responsable: cuando nadie decide, pero alguien paga"
date: 2026-02-22
categories: [IA, Tecnología, Cultura]
tags: [IA, Responsabilidad, Gobernanza, Complejidad]
description: "Cómo delegar en la IA diluye la responsabilidad y redefine quién decide en una organización."
featureimage: "/images/posts/2026-02-22-decisiones-sin-responsable/feature.png"
---

# Decisiones sin responsable: cuando nadie decide, pero alguien paga

![Ilustracion sobre decisiones desconectadas](/images/posts/2026-02-22-decisiones-sin-responsable/feature.png)

Hay un momento, casi imperceptible, en el que una organización deja de decidir como siempre lo había hecho y empieza a hacerlo de otra forma. No hay anuncio oficial ni comunicado interno. No hay un “antes y después” claro. Simplemente, un día, alguien propone una idea y la respuesta es:

> “Vamos a preguntarle a la IA.”

Al principio suena razonable. Incluso sensato.  
¿Por qué no hacerlo, si la herramienta existe, responde rápido y parece saber de qué habla?

La caja negra con sonrisa entra así en la conversación, no como una autoridad explícita, sino como una ayuda. Un apoyo. Un atajo.

El problema es que los atajos, cuando se convierten en costumbre, acaban redibujando el camino.

![Ilustracion sobre atajos que redibujan decisiones](/images/posts/2026-02-22-decisiones-sin-responsable/scene-1.png)

En muchas organizaciones, la primera experiencia con la IA es deslumbrante.  
Un directivo sube un documento de cientos de páginas —una licitación, un informe, una propuesta compleja— y en segundos obtiene un resumen claro, un análisis estructurado o incluso un plan de implementación. La sensación es inmediata: *esto funciona*.

Y funciona, de verdad.

La IA es extraordinariamente buena en tareas de síntesis, redacción, reorganización del lenguaje y framing de ideas. Ahí juega en casa. No es magia ni engaño. Es exactamente para lo que ha sido entrenada.

El problema empieza cuando esa experiencia se extrapola, casi sin darse cuenta, a otro tipo de trabajo completamente distinto.

Porque no todos los problemas son problemas de lenguaje.

Cuando un técnico trabaja en una arquitectura, en una infraestructura o en un sistema que va a producción, no está buscando una respuesta plausible. Está buscando algo mucho más incómodo: una solución correcta, coherente con su contexto, mantenible en el tiempo y con consecuencias conocidas.

Ahí ya no basta con que algo “suene bien”.

Ahí entran en juego decisiones que no siempre están escritas en ningún sitio:
- convenciones locales,
- estándares tácitos,
- aprendizajes acumulados tras errores pasados,
- límites que solo se conocen después de haberlos cruzado una vez.

Ese conocimiento no suele estar en la documentación oficial. Vive en las personas.

![Ilustracion sobre conocimiento tacito en personas](/images/posts/2026-02-22-decisiones-sin-responsable/scene-2.png)

Para ganar velocidad, muchas organizaciones han tomado una decisión aparentemente lógica: pedir a los técnicos que usen la IA de forma sistemática. Que escriba código, que genere infraestructura, que documente sistemas. El argumento es sencillo: si la IA escribe más rápido, el técnico solo tiene que revisar.

En teoría, es una mejora clara.

En la práctica, revisar no es leer. Revisar es **entender profundamente algo que no has diseñado tú**, detectar supuestos implícitos, reconstruir decisiones que nadie ha explicado y comprobar que todo encaja en un sistema que ya existía antes de que la caja escribiera una sola línea.

Eso no es más barato que crear desde cero.  
A menudo, es más caro.

Y, aun así, se asume que el técnico debe hacerlo en menos tiempo, porque “la IA ya ha hecho la parte difícil”.

Aquí aparece una de las tensiones más importantes de todo este debate: **la responsabilidad**.

Aunque la IA genere el código, aunque proponga la arquitectura, aunque escriba la documentación, la responsabilidad final sigue siendo humana. Si algo falla en producción, no falla el modelo. No falla la caja. Falla la persona que revisó, aprobó y firmó.

Esa persona es quien responde ante incidentes, quien da explicaciones y quien carga con las consecuencias.

Pero muchas veces, esa misma persona:
- no ha tenido autoridad real para decir “esto no”,
- no ha podido marcar los límites del uso de la IA,
- no ha contado con el tiempo necesario para revisar con criterio,
- y ha trabajado bajo la presión explícita de ir más rápido.

La ecuación es peligrosa:
> **autoría difusa + responsabilidad total**

![Ilustracion sobre autoria difusa](/images/posts/2026-02-22-decisiones-sin-responsable/scene-3.png)

Cuando eso se normaliza, la organización empieza a decidir sin darse cuenta de que ya no sabe muy bien quién está decidiendo.

Este modelo tiene efectos secundarios que no se ven en el corto plazo.

Los técnicos seniors, con más experiencia, acaban actuando como amortiguadores del sistema. Son quienes corrigen, refactorizan, apagan fuegos y asumen la carga cognitiva de integrar lo que la caja produce. Poco a poco, su trabajo deja de ser diseñar y pasa a ser validar a contrarreloj.

Los juniors, por su parte, aprenden a interactuar con la IA antes de haber construido un criterio propio. Preguntan, obtienen respuestas y ven que las cosas funcionan… sin entender por qué. Y cuando algo funciona sin comprensión, no se genera aprendizaje. Solo dependencia.

La organización, mientras tanto, empieza a asumir que “la IA lo hace mejor”, reduciendo espacios de aprendizaje justo en el punto donde se forma el relevo generacional.

El resultado no es inmediato, pero es previsible:  
menos criterio distribuido, más dependencia de sistemas opacos y una fragilidad creciente ante cualquier cambio.

Nada de esto implica que la IA sea el problema.

La IA es una herramienta potente y, bien utilizada, puede mejorar muchísimo la forma en la que trabajamos. Pero como cualquier herramienta poderosa, **tiene un ámbito de uso donde aporta valor y otro donde introduce riesgo**.

El conflicto aparece cuando se usa fuera de ese ámbito sin haber redefinido:
- cómo se toman las decisiones,
- quién tiene autoridad para frenarlas,
- cómo se forma a quienes empiezan,
- y quién asume realmente las consecuencias.

Porque cuando una decisión sale bien, siempre hay alguien dispuesto a celebrarla.  
Pero cuando sale mal, alguien acaba pagando el precio.

Y en demasiados casos, ese alguien:
- no decidió,
- no tuvo autoridad,
- no tuvo tiempo,
- pero sí tuvo que responder.

![Ilustracion sobre quien paga el precio](/images/posts/2026-02-22-decisiones-sin-responsable/scene-4.png)

Quizá dentro de un mes la caja lo haga todo perfecto.  
Ojalá.

Quizá dentro de un año miremos atrás y pensemos que estas dudas eran exageradas.  
Ojalá también.

No tengo ningún problema en estar equivocado.  
De hecho, sería una gran noticia.

Lo que sí me preocupa es que estemos tomando decisiones irreversibles —organizativas, humanas y estratégicas— **antes de entender realmente qué estamos delegando**.

Porque las organizaciones que deciden más rápido de lo que entienden  
no se vuelven más innovadoras.  
Se vuelven más frágiles.

Y la fragilidad, cuando escala, no suele dar segundas oportunidades.

---

{{< smallnote >}}
**Nota**: Este artículo forma parte de una serie que reflexiona sobre el uso real de la IA en entornos profesionales. No pretende frenar su adopción, sino ayudar a utilizarla donde aporta valor y a cuestionarla donde introduce riesgos que aún no estamos midiendo.
{{< /smallnote >}}
