# Juniors, aprendizaje y el riesgo de una generación que no entiende lo que funciona

Toda generación aprende con las herramientas que tiene a mano.  
Nosotros aprendimos con buscadores, foros, documentación incompleta y respuestas que empezaban con “esto no es buena práctica, pero…”.

Nada de eso era cómodo.  
Pero había una norma no escrita que se cumplía casi siempre:  
si algo funcionaba, tarde o temprano tenías que entender por qué.

Con la IA, esa norma empieza a resquebrajarse.

Hoy muchos juniors no buscan. Preguntan.  
No investigan. Solicitan.  
No prueban hipótesis. Esperan respuestas.

La caja negra con sonrisa está siempre disponible, no se cansa, no juzga y responde con una seguridad envidiable. Le preguntas algo y te devuelve código, explicaciones y hasta comentarios bien redactados. A veces incluso añade emojis, por si dudabas de su buena intención.

Y, para incomodidad de muchos seniors, **muchas veces funciona**.

Aquí conviene aclarar algo desde el principio, para evitar malentendidos:  
los juniors **no son víctimas inocentes** de esta situación.

La IA no les obliga a aceptar respuestas sin cuestionarlas.  
No les impide abrir la documentación oficial.  
No les prohíbe pararse a entender.

Como cualquier otro profesional, toman decisiones. Y una de ellas es decidir si quieren saber por qué algo funciona… o si les basta con que funcione.

Durante años hemos repetido el mismo mantra sobre el copia y pega:  
*“Si copias código sin entenderlo, tarde o temprano lo pagarás.”*

La IA no elimina ese problema.  
Lo hace más cómodo.

Ahora el código no viene de un hilo caótico de Stack Overflow, sino de una respuesta elegante, estructurada y aparentemente razonada. Ya no hay variables con nombres crípticos ni comentarios en ruso. Todo parece limpio. Profesional. Confiable.

Y eso es precisamente lo peligroso.

El junior ejecuta el código, pasa los tests básicos y ve que todo funciona. Sonríe. La caja también. Se hace el commit. Se avanza.

Pero cuando alguien pregunta:
> “¿Por qué esto está hecho así?”

La respuesta es vaga.  
O inexistente.

No porque el junior no sea capaz, sino porque **nunca recorrió el camino mental que lleva a esa decisión**. La caja lo hizo por él.

Y el aprendizaje no ocurre cuando algo funciona.  
Ocurre cuando entiendes por qué podría haber fallado.

Aquí aparece un riesgo del que se habla poco: la **atrofia del criterio**.

El criterio no se descarga.  
No viene en un prompt.  
No aparece mágicamente después de suficientes iteraciones con la IA.

Se construye a base de:
- equivocarse,
- investigar causas,
- comparar alternativas,
- y asumir las consecuencias de las decisiones.

Cuando ese proceso se sustituye por una interacción constante con la caja, el junior aprende a *operar la herramienta*, pero no necesariamente a *pensar el sistema*.

Aprende a ajustar prompts.  
No a modelar problemas.


Conviene decirlo sin rodeos:  

> ***Saber usar la IA no equivale a saber ingeniería***.

Un junior que solo sabe pedirle cosas a la caja no está creciendo más rápido. Está creciendo de forma diferente… y no necesariamente en la dirección correcta.

Y aquí las organizaciones pueden ayudar a impulsar el desastre.

Si se premia la velocidad por encima del entendimiento, si el mensaje implícito es “mientras funcione, adelante”, no debería sorprender que los juniors optimicen exactamente para eso.

Pero incluso en ese contexto, hay una responsabilidad individual que no se puede delegar.

Usar la IA de forma productiva como junior implica aceptar una verdad incómoda:

> **Si no puedes explicar por qué algo funciona,  
> no lo entiendes todavía.**

Eso no significa escribir todo desde cero ni rechazar la herramienta. Significa usarla como lo que es: un asistente. Un acelerador. No un sustituto del pensamiento.

Preguntar *qué otras opciones hay*.  
Contrastar con documentación oficial.  
Modificar el código y ver qué se rompe.  
Pararse a entender antes de seguir avanzando.

La IA puede acompañar ese proceso.  
Pero no puede recorrerlo por ti.

El problema de fondo no es que la IA “reemplace” a los juniors.  
Eso es una simplificación más.

El riesgo real es formar una generación extremadamente eficiente…  
y peligrosamente superficial.

Profesionales que producen resultados rápidos,  
pero no entienden los sistemas que mantienen.  
Que ejecutan bien,  
pero dudan cuando algo se sale del guion.

Una generación que sabe hablar con la caja,  
pero no discutirle.

Y cuando dentro de unos años necesitemos seniors con criterio,  
con memoria de errores pasados  
y con capacidad de decidir bajo incertidumbre,  
descubriremos —demasiado tarde—  
que nadie se convirtió en eso solo preguntando bien.

---

{{< smallnote >}}
**Nota**: Este artículo no pretende demonizar a los juniors ni a la IA. Pretende recordar que el aprendizaje profesional no se puede automatizar sin coste. La herramienta puede acelerar el camino, pero no sustituirlo sin consecuencias.
{{< /smallnote >}}
